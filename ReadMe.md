### 是不是任何网络结构都可以用全连接网络来代替，验证结果是有很大可能。需要确定数据和模型
## 模型结构学习，是否可以避免原始模型缺点同时增加一些可变动的因素

使用XGboost结构训练NN实现线上模型转化  拆分树获取树的输出和叶结构分布

## 如何理解NN的超强表征能力
在NN考虑一个神经元，单个神经元的输出`y=wx+b`,激活函数是`g=max(x,0)`,在这个神经元的输出为`max(wx+b,0)` 也就是relu函数，relu函数的拐点和斜率  
由`w`和`b`决定，一层有很多神经元，可以生成很多不同斜率和不同拐点的relu，当这些relu进行叠加后会生成各种各样的函数形式。简单来说就是无数个小函数  
可以叠加成一个复杂函数，  
w1\*max(wx+b)+w2\*max(wx+b)+w3\*max(wx+b)+w4\*max(wx+b),四个神经元的输出图像以某个比例进行求和可以得到一个非常复杂的函数图像。  
起始的图像是 ![Relu](/img/relu.png)
